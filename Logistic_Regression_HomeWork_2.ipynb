{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Resize, ToTensor, Compose, Normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия на MNIST\n",
    "\n",
    "В этом задании мы напишем свой классификатор картинок - с помощью одной лишь логистической регрессии.\n",
    "Мы возьмем известный датасет MNIST - набор из 60 000 картинок рукописных цифр от 0 до 9. Задача модели  - получая на вход серую картинку размером 28*28 пикселей с нарисованой на ней цифрой - определить что это за цифра.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы накладываем серию транфсормаций для каждой картинки - сначала переводим их в тензор, а затем делаем нормализацию значений пикселей.\n",
    "Сейчас они (пиксели) находятся в интервале от 0 до 255 - мы сократим это расстояние, и установить среднее значение как 0, а стандартное отклонение - 1.\n",
    "\n",
    "В tochvision есть специальный модуль transfroms в котором уже реализовано большинство трасформаций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.0], std=[1.0])]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST является стандартным датасетом и поэтому мы легко импортируем его из библиотеки torchvision.\n",
    "Он находиться в специальном понятном для Pytorch формате Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_train = MNIST('./', download=True, train=True, transform=transform)\n",
    "data_test = MNIST('./', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb2c229ced0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data_test.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Logistic Regression* - это все та же линейная регрессия + функция активации \n",
    "\n",
    "В случае бинарной классификации (когда модель учится только на двух категориях) - эта функция - Sigmoid или [логистическая функция](https://ru.wikipedia.org/wiki/%D0%9B%D0%BE%D0%B3%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D1%83%D1%80%D0%B0%D0%B2%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5)\n",
    "\n",
    "Если у нас классов больше чем два - вместо сигмоиды мы можем использовать функцию [SoftMax](https://ru.wikipedia.org/wiki/Softmax).\n",
    "Это версия той же логистической функции, но только для многомерного случая.\n",
    "\n",
    "Она нормализирует выходные значения сети, чтобы те были в интервале от 0 до 1 и их сумма была равна 1.\n",
    "В таком виде выходные значения можно интерпретировать как \"вероятности\" - на сколько вероятно модель считает верным тот или иной класс.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=0):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = torch.exp(x - torch.max(x))\n",
    "    return e_x / e_x.sum(axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1:\n",
    "Напишите функцию логистической регресии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(x, W):\n",
    "    \n",
    "    z = x@W\n",
    "#    y = softmax(z)\n",
    "    y = torch.softmax(z, 1)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выходные значения нашей модели будут выглядеть как вектор вероятностей:\n",
    "\n",
    "[0.8, 0.2, ... , 0.001] - где индекс вероятности в векторе соответствует номеру класса.\n",
    "Например, в векторе выше 0.8 это вероятность того что число на картинке - 0, 0.2 - что 1 и так далее.\n",
    "\n",
    "#### Задание 1.2 Прочитать более детально про кросс-ентропию\n",
    "https://gombru.github.io/2018/05/23/cross_entropy_loss/\n",
    "\n",
    "https://peterroelants.github.io/posts/cross-entropy-softmax/\n",
    "\n",
    "\n",
    "\n",
    "## Напишите код для мультиклассовой кросс-энтропиии\n",
    "\n",
    "Здесь вы найдете правильную реализацию, если запутаетесь\n",
    "https://gist.github.com/ArtemCLime/18ebb1adafe95631e9f2ff9cf8b2df99\n",
    "\n",
    "НО постарайтесь НЕ ИСПОЛЬЗОВАТЬ ее, а попробовать написать функцию самостоятельно, используя источники выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кросс-энтропия для мультиклассового случая\n",
    "\n",
    "def cross_entropy_loss(y_hat, y_true):\n",
    "    # Выбираем вероятности для правильных классов\n",
    "    logits_for_answers = y_hat[np.arange(len(y_hat)),  y_true]\n",
    "    \n",
    "    # Считаем кросс-ентропию для каждого из классов\n",
    "    xentropy = -torch.log(logits_for_answers)\n",
    "    return xentropy.sum() / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для проверки используйте этот кусок кода - числа у вашей кросс-ентропии и pytorch-реализации должны совпасть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.1562), tensor(1.1562))"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = tensor([[0.1, 0.1, 0.8], [0.1, 0.5, 0.4], [0.3, 0.3, 0.4]])\n",
    "y_true = tensor([0, 1, 0])\n",
    "\n",
    "cross_entropy_loss(torch.softmax(y_hat, -1), y_true), torch.nn.functional.cross_entropy(y_hat, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2:\n",
    "Напишите функцию для градиентного спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(W, learning_rate):\n",
    "    # Your code here\n",
    "    with torch.no_grad():\n",
    "      W.sub_(learning_rate * W.grad)  # Weights update\n",
    "      W.grad.zero_() # Zero gradient\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3:\n",
    "Напишите функцию для подсчета точности\n",
    "\n",
    "Hint: Функция argmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_hat, y_true):\n",
    "    # Your code here\n",
    "#    accuracy = torch.argmax(y_hat).float().mean()\n",
    "    y_hat = torch.argmax(y_hat, dim=1)\n",
    "    return (y_hat == y_true).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мы \"растягиваем\" нашу картинку 28*28 в один длинный вектор размером 784, для нашей логистической регресии\n",
    "# Задание 3.5 - почитайте про .view метод в PyTorch и разберитесь как он действует\n",
    "\n",
    "def preprocess_data(x):\n",
    "    return x.view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4:\n",
    "Заполните сколько у нас фичей для каждой картинки и сколько классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 784\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "\n",
    "W = torch.nn.Parameter(torch.ones(NUM_FEATURES, NUM_CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5:\n",
    "Напишите функцию для обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_data, W, learning_rate):\n",
    "    \n",
    "    losses = []\n",
    "    scores = []\n",
    "    \n",
    "    for x, y in train_data:\n",
    "        x = preprocess_data(x)\n",
    "        \n",
    "        y_hat = logistic_regression(x, W)\n",
    "\n",
    "        loss = cross_entropy_loss(y_hat, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        W = gradient_descent(W, learning_rate)\n",
    "       \n",
    "        losses.append(loss.item())\n",
    "        scores.append(score(y_hat, y))\n",
    "    return W, np.mean(losses), np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6:\n",
    "Напишите функцию для тестирования модели\n",
    "Hint (во время тестиования мы не обновляем веса)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(test_data, W):\n",
    "    losses = []\n",
    "    scores = []\n",
    "    \n",
    "    for x, y in test_data:\n",
    "        x = preprocess_data(x)\n",
    "           \n",
    "        y_hat = logistic_regression(x, W)\n",
    "\n",
    "        loss = cross_entropy_loss(y_hat, y)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        scores.append(score(y_hat, y))\n",
    "    return np.mean(losses), np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы используем класс DataLoader от Pytorch - он позволяет нам удобно и быстро читать датасет батчами\n",
    "Учитывая простоту модели мы можем брать батчи по-больше - даже на СРU это не займет много времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataLoader(data_train, batch_size=256)\n",
    "test = DataLoader(data_test, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7:\n",
    "Подберите гиперпараметры - количество епох и learning rate для наилучших результатов.\n",
    "На данном датасете вы можете набрать более 0.9 точности даже с такой простой моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0\n",
      "Train Accuracy: 0.8736259341239929, train loss: 0.46342650379272216\n",
      "Test Accuracy: 0.9013557434082031, test loss: 0.34756793081760406\n",
      "##########\n",
      "Epoch #1\n",
      "Train Accuracy: 0.9050753712654114, train loss: 0.33659019077077823\n",
      "Test Accuracy: 0.9095473289489746, test loss: 0.3197407938539982\n",
      "##########\n",
      "Epoch #2\n",
      "Train Accuracy: 0.9109929800033569, train loss: 0.31682583683348714\n",
      "Test Accuracy: 0.9116727709770203, test loss: 0.3090470261871815\n",
      "##########\n",
      "Epoch #3\n",
      "Train Accuracy: 0.9144670367240906, train loss: 0.30638821562553975\n",
      "Test Accuracy: 0.9140912294387817, test loss: 0.3032784044742584\n",
      "##########\n",
      "Epoch #4\n",
      "Train Accuracy: 0.9172872304916382, train loss: 0.29953929258787887\n",
      "Test Accuracy: 0.9150563478469849, test loss: 0.29961206689476966\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "W = torch.nn.Parameter(torch.ones(NUM_FEATURES, NUM_CLASSES))\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "learning_rate = 0.5\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    W, train_loss, train_accuracy = train_epoch(train, W, learning_rate)\n",
    "    \n",
    "    test_loss, test_accuracy = test_epoch(test, W)\n",
    "\n",
    "    print (f'Epoch #{i}')\n",
    "    print (f'Train Accuracy: {train_accuracy}, train loss: {train_loss}')\n",
    "    print (f'Test Accuracy: {test_accuracy}, test loss: {test_loss}')\n",
    "    print (\"#\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Поздравляю, все получилось!\n"
     ]
    }
   ],
   "source": [
    "if (test_accuracy) > 0.9:\n",
    "    print (\"Поздравляю, все получилось!\")\n",
    "else:\n",
    "    print (\"Стоит еще попробовать!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
